# An Attempt at Detecting knowldege inconsistencies in smaller models with limited compute
### Based on Wan et al., 2024, "Knowledge verification to nip hallucination in the bud". Excluding fine-tuning of models, thus limited to investigation of knowledge inconsistencies between alignment data and foundation models and estimation of hallucination rates.

Using (slightly) modified code from https://github.com/fanqiwan/KCA and Tiny-LLM. Please clone all repositories mentioned in the Notebook.
